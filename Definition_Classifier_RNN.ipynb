{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Definition Classifier - RNN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUCMhdAxsXN1",
        "colab_type": "code",
        "outputId": "92e8af6f-31a2-4700-ad67-d8b2d8639649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import numpy as np\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AduWhNyKrXel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim import utils\n",
        "import os\n",
        "\n",
        "def getDataAsString(path):\n",
        "  data=[]\n",
        "  labels = []\n",
        "  directory = os.fsencode(path)\n",
        "\n",
        "  for file in os.listdir(directory):\n",
        "    filename = os.fsdecode(file)\n",
        "    if filename.endswith(\".deft\"): \n",
        "      \n",
        "      filename=path+filename  \n",
        "      with open(filename) as fp:\n",
        "        line = fp.readline()\n",
        "        while line:\n",
        "          l=line.strip()\n",
        "          labels.append(int(l[len(l)-2]))\n",
        "          if(len(utils.simple_preprocess(l))==0):\n",
        "            data.append(\" \".join(utils.simple_preprocess('hamada')))\n",
        "          else:\n",
        "            data.append(\" \".join(utils.simple_preprocess(l)))\n",
        "          \n",
        "          line = fp.readline()\n",
        "  return data, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k8ag4uSaOAN",
        "colab_type": "code",
        "outputId": "c012f885-4070-4465-8968-4be5c28782f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "corpus, y_train = getDataAsString('drive/My Drive/deft_train/')\n",
        "testData, y_test = getDataAsString('drive/My Drive/deft_test/')\n",
        "\n",
        "print(\"Train Data: \", len(corpus))\n",
        "\n",
        "encoder = tfds.features.text.SubwordTextEncoder.build_from_corpus(corpus, target_vocab_size=10000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Data:  18157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XanJXrzIgEK2",
        "colab_type": "code",
        "outputId": "a50ea320-5eb6-4787-cdf0-9a4a81305201",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "def zeroPad(data, encodedArray, max):\n",
        "  docs=np.zeros((len(data),max))\n",
        "  for i in range(len(encodedArray)):\n",
        "    docs[i][0:len(encodedArray[i])]+=encodedArray[i]\n",
        "  return docs\n",
        "\n",
        "\n",
        "def encodeDataAndPad():\n",
        "  encodedTrain = []\n",
        "  max = 0\n",
        "  for sent in corpus:\n",
        "    encodedTrain.append(encoder.encode(sent))\n",
        "    if len(encodedTrain[-1])>max:\n",
        "      max = len(encodedTrain[-1])\n",
        "\n",
        "  docsTrain = zeroPad(corpus, encodedTrain, max)\n",
        "  print(docsTrain.shape)\n",
        "\n",
        "\n",
        "  encodedTest = []\n",
        "  for sent in testData:\n",
        "    encodedTest.append(encoder.encode(sent))\n",
        "\n",
        "  docsTest = zeroPad(testData, encodedTest, max)\n",
        "\n",
        "  trainLabels=np.array(y_train).reshape((-1,1))\n",
        "  testLabels=np.array(y_test).reshape((-1,1))\n",
        "\n",
        "\n",
        "  return docsTrain, trainLabels, docsTest, testLabels\n",
        "\n",
        "\n",
        "docsTrain, y_train, docsTest, y_test = encodeDataAndPad()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(18157, 113)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFgzmTxoqye8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Vx4_FjgrHbk",
        "colab_type": "code",
        "outputId": "9395f2c4-c0af-44a8-d3b0-49c568479231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import LSTM, Flatten, Dense, Dropout, Masking, Embedding, BatchNormalization\n",
        "from keras import regularizers\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(encoder.vocab_size, 128),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "    # tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    # tf.keras.layers.BatchNormalization(),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4), metrics=['acc',f1_m,precision_m, recall_m])\n",
        "\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 128)         1275520   \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 256)               263168    \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_29 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,557,249\n",
            "Trainable params: 1,557,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Igx6CgwCrKpp",
        "colab_type": "code",
        "outputId": "02be77f6-5a09-4b2d-8dd4-27f102a16c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.best2.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_f1_m', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "history  = model.fit(docsTrain, y_train, batch_size=64,  epochs=10, validation_split=0.1,callbacks=callbacks_list)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 16341 samples, validate on 1816 samples\n",
            "Epoch 1/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.6261 - acc: 0.6646 - f1_m: 0.0088 - precision_m: 0.0400 - recall_m: 0.0078\n",
            "Epoch 00001: val_f1_m improved from -inf to 0.10610, saving model to weights.best2.hdf5\n",
            "16341/16341 [==============================] - 10s 641us/sample - loss: 0.6260 - acc: 0.6646 - f1_m: 0.0097 - precision_m: 0.0438 - recall_m: 0.0083 - val_loss: 0.5537 - val_acc: 0.7142 - val_f1_m: 0.1061 - val_precision_m: 0.4598 - val_recall_m: 0.0628\n",
            "Epoch 2/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.4884 - acc: 0.7621 - f1_m: 0.5488 - precision_m: 0.7393 - recall_m: 0.4768\n",
            "Epoch 00002: val_f1_m improved from 0.10610 to 0.56288, saving model to weights.best2.hdf5\n",
            "16341/16341 [==============================] - 8s 467us/sample - loss: 0.4885 - acc: 0.7621 - f1_m: 0.5491 - precision_m: 0.7403 - recall_m: 0.4767 - val_loss: 0.4554 - val_acc: 0.7869 - val_f1_m: 0.5629 - val_precision_m: 0.6312 - val_recall_m: 0.5344\n",
            "Epoch 3/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8268 - f1_m: 0.7215 - precision_m: 0.7720 - recall_m: 0.6916\n",
            "Epoch 00003: val_f1_m improved from 0.56288 to 0.57575, saving model to weights.best2.hdf5\n",
            "16341/16341 [==============================] - 8s 464us/sample - loss: 0.3842 - acc: 0.8269 - f1_m: 0.7221 - precision_m: 0.7729 - recall_m: 0.6920 - val_loss: 0.4689 - val_acc: 0.7803 - val_f1_m: 0.5758 - val_precision_m: 0.6297 - val_recall_m: 0.5660\n",
            "Epoch 4/10\n",
            "16256/16341 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.8666 - f1_m: 0.7923 - precision_m: 0.8180 - recall_m: 0.7797\n",
            "Epoch 00004: val_f1_m improved from 0.57575 to 0.61048, saving model to weights.best2.hdf5\n",
            "16341/16341 [==============================] - 8s 465us/sample - loss: 0.3144 - acc: 0.8663 - f1_m: 0.7920 - precision_m: 0.8183 - recall_m: 0.7789 - val_loss: 0.4931 - val_acc: 0.7814 - val_f1_m: 0.6105 - val_precision_m: 0.6075 - val_recall_m: 0.6467\n",
            "Epoch 5/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.2646 - acc: 0.8911 - f1_m: 0.8317 - precision_m: 0.8493 - recall_m: 0.8248\n",
            "Epoch 00005: val_f1_m did not improve from 0.61048\n",
            "16341/16341 [==============================] - 8s 459us/sample - loss: 0.2645 - acc: 0.8911 - f1_m: 0.8319 - precision_m: 0.8495 - recall_m: 0.8251 - val_loss: 0.5615 - val_acc: 0.7682 - val_f1_m: 0.6050 - val_precision_m: 0.5925 - val_recall_m: 0.6675\n",
            "Epoch 6/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.2222 - acc: 0.9118 - f1_m: 0.8644 - precision_m: 0.8747 - recall_m: 0.8623\n",
            "Epoch 00006: val_f1_m did not improve from 0.61048\n",
            "16341/16341 [==============================] - 7s 456us/sample - loss: 0.2223 - acc: 0.9118 - f1_m: 0.8643 - precision_m: 0.8741 - recall_m: 0.8628 - val_loss: 0.5851 - val_acc: 0.7781 - val_f1_m: 0.6086 - val_precision_m: 0.6189 - val_recall_m: 0.6433\n",
            "Epoch 7/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9289 - f1_m: 0.8908 - precision_m: 0.8957 - recall_m: 0.8922\n",
            "Epoch 00007: val_f1_m did not improve from 0.61048\n",
            "16341/16341 [==============================] - 7s 458us/sample - loss: 0.1859 - acc: 0.9289 - f1_m: 0.8906 - precision_m: 0.8955 - recall_m: 0.8920 - val_loss: 0.6977 - val_acc: 0.7434 - val_f1_m: 0.6067 - val_precision_m: 0.5411 - val_recall_m: 0.7325\n",
            "Epoch 8/10\n",
            "16256/16341 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9433 - f1_m: 0.9130 - precision_m: 0.9187 - recall_m: 0.9133\n",
            "Epoch 00008: val_f1_m did not improve from 0.61048\n",
            "16341/16341 [==============================] - 7s 450us/sample - loss: 0.1563 - acc: 0.9432 - f1_m: 0.9131 - precision_m: 0.9186 - recall_m: 0.9135 - val_loss: 0.7311 - val_acc: 0.7594 - val_f1_m: 0.5967 - val_precision_m: 0.5840 - val_recall_m: 0.6544\n",
            "Epoch 9/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9529 - f1_m: 0.9283 - precision_m: 0.9291 - recall_m: 0.9315\n",
            "Epoch 00009: val_f1_m did not improve from 0.61048\n",
            "16341/16341 [==============================] - 8s 475us/sample - loss: 0.1324 - acc: 0.9528 - f1_m: 0.9280 - precision_m: 0.9288 - recall_m: 0.9312 - val_loss: 0.7813 - val_acc: 0.7555 - val_f1_m: 0.5764 - val_precision_m: 0.5874 - val_recall_m: 0.6099\n",
            "Epoch 10/10\n",
            "16320/16341 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9610 - f1_m: 0.9404 - precision_m: 0.9426 - recall_m: 0.9412\n",
            "Epoch 00010: val_f1_m did not improve from 0.61048\n",
            "16341/16341 [==============================] - 7s 449us/sample - loss: 0.1130 - acc: 0.9610 - f1_m: 0.9405 - precision_m: 0.9424 - recall_m: 0.9415 - val_loss: 0.8633 - val_acc: 0.7528 - val_f1_m: 0.6016 - val_precision_m: 0.5704 - val_recall_m: 0.6831\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duBDbbxKrm4y",
        "colab_type": "code",
        "outputId": "692f04c9-14ed-4f91-bae1-5e99c16ae5e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "from sklearn.metrics import f1_score,classification_report\n",
        "\n",
        "model.load_weights(\"weights.best2.hdf5\")\n",
        "loss, accuracy, f1_score, precision, recall  = model.evaluate(docsTest, y_test,verbose=1)\n",
        "\n",
        "print(\"Accuracy: \", accuracy)\n",
        "print(\"f1: \", f1_score)\n",
        "\n",
        "y_predicted = model.predict_classes(docsTest)\n",
        "\n",
        "print(classification_report(y_test, y_predicted))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "853/853 [==============================] - 0s 259us/sample - loss: 0.4696 - acc: 0.7726 - f1_m: 0.6175 - precision_m: 0.6395 - recall_m: 0.6202\n",
            "Accuracy:  0.7725674\n",
            "f1:  0.61753833\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       573\n",
            "           1       0.66      0.62      0.64       280\n",
            "\n",
            "    accuracy                           0.77       853\n",
            "   macro avg       0.74      0.73      0.74       853\n",
            "weighted avg       0.77      0.77      0.77       853\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAuxok34G6AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}